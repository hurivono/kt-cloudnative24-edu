Airflow vs Azure Airflow (AKS, ADF, ISV Service)

Airflow란? Airbnb의 엔지니어링팀에서 개발한 오픈 소스 워크플로우 관리 플랫폼

주로 데이터 파이프라인의 자동화, 스케쥴링, 모니터링에 사용 or 배치나 데몬을 스케쥴링하고 자동화 실행할 수 있는 장점이 있기 때문에 다양한 목적으로 사용

ICIS TR 프로젝트 → 배치, 데몬 위주의 스케쥴링 및 모니터링 등에 사용중

Airflow 구성
DAG(Directed Acyclic Graph) : 순환하지 않는 단방향 그래프. 작업과 작업과의 의존성, 순서를 정의하는 워크플로우, 노드와 엣지로 구성
Operator : Operator는 각 작업을 정의하는 구성요소. PythonOperator, BashOperator, HttpOperator, SqlOperater 등 다양한 종류의 Operator가 있어서 다양한 작업을 실행할 수 있도록 정의 가능
Scheduler : 스케쥴러는 DAG에서 정의된 실행 일정에 따라서 작업을 예약하고 실행하는 요소

[Airflow 동작 흐름도]

UI를 통해 Webserver container에 접근
Webserver가 DAG Trigger 수행
Scheduler와 Executor를 구동
Scheduler는 Metadata DB에서 DAG과 Task의 상태 check.
Executor에게 실행 가능한 Task를 전달. Executor는 task를 worker에게 전달.
Worker는 Task를 실제 수행
로그 Metadata DB에 기록
Azure의 Airflow (AKS, ADF, ISV Service)
ADF (Azure Data Factory) 소개

ADF는 MS에서 개발한 클라우드 기반 ETL 데이터 통합 서비스
조직내 다양한 소스에서 데이터를 추출, 변환, 로드해서 분석할 수 있고, 데이터 파이프라인을 만들고, 스케쥴링 및 관리를 수행
ADF는 같은 Cloud인 Azure의 데이터 소스와 연결, 외부 데이터 소스 연결 모두 가능하고 다양한 소스의 데이터를 쉽게 모아 통합 view를 구성 할 수 있음
노코드로 data flow 구축 및 관리 가능

Data Source에서 온프레미스의 데이터 또는 외부 데이터를 가져와서 읽고 ADF로 데이터 ETL 수행, 이후 분석이나 시각화에 이용할 수 있다.

이때 ADF의 Orchestration 중 Airflow를 사용해 파이프라인을 구성하고 스케쥴링, 관리하는 기능을 사용하려고 했었다.

ADF의 Airflow는 현재 새 환경 구성을 지원하지 않고 있으며, MS의 Fabric이라는 솔루션으로 대체하길 권고하고 있다.

ICIS TR의 Airflow와 Fabric의 기능이 일치하는지 확인하기 어렵고, Fabric 리소스를 이용하는데에 약 6천달러정도의 비용이 들기 때문에 당장의 테스트에서는 사용하지 못했음.




Azure Airflow ISV Service 소개
ISV Service란? 

ISV Service는 타 벤더사의 완성 소프트웨어를 Azure에서 사용하는 서비스를 뜻함.
Azure에서 쉽게 해당 SW를 사용할 수 있도록 프로비저닝, 관리 등을 구성한 Service
Apache Airflow™ on Astro - An Azure Native ISV Service
ISV Service Airflow의 경우 Astro Organization을 만들어야 Airflow를 구성할 수 있음.
Astro Organization은 Azure Airflow의 기본 단위.
Astro : Airflow를 관리하는 리소스 단위
Astro Organization : Azure Airflow의 기본 단위
Astro Organization로 Airflow의 리소스를 생성하고, 관리함. 여러 Airflow에 대해 구성인원에게 역할 할당 및 비용 관리, 모니터링을 수행할 수 있음. 일반 로컬에서 사용하는 솔루션 단위의 Airflow보다 대규모 프로젝트에 적합




데이터분석 팀이 있다면 Astro Organization이라는 기본 단위로 Airflow 인스턴스를 만들고, 해당 인스턴스의 여러 권한을 팀원들에게 부여할 수도 있음. 즉, 인스턴스, 역할, 비용 관리를 효율적으로 수행할 수 있도록 도와주는 단위라고 볼 수 있음.




ISV Service Airflow 지원 기능

Airflow의 기능을 확장하고 사용자가 쉽게 데이터 파이프라인을 관리할 수 있도록 돕는다.

Worker/Scheduler Auto Scaling, monitoring, logging, secure
제어 평면 : 사용자 인터페이스(UI), API, CLI를 통해 프로비저닝, 관리 수행.
데이터 평면 : 실제 Airflow가 실행되는 환경. Astro는 K8S 클러스터를 사용해서 Airflow 인스턴스를 실행함.
Airflow 버전 자동 업그레이드
배포 관리, 클러스터 관리, 사용자 관리




Airflow vs Azure Airflow

	

Airflow

(Local)

	

Azure Airflow

(ADF Orchestration)

	

Azure Airflow

(ISV Service)

	

Airflow

(AKS)


배포 방식	사용자가 직접 VM, 컨테이너, 혹은 Kubernetes 클러스터에 배포	Azure Data Factory 내에서 Airflow 실행 지원	

Apache Airflow™ on Astro - An Azure Native ISV Service 솔루션으로 제공

	Azure Kubernetes Service 클러스터 위에 Helm 차트 또는 Kubernetes manifest로 배포
확장성	Kubernetes 기반으로 설정 시 확장 가능 	Azure에서 확장 가능하나, 고급 설정은 제한적	

ISV 제공자에 따라 유동적

(Airflow의 경우 확장 범위 불분명하여 확인 필요)

	AKS의 스케일링 기능으로 확장 가능 (노드 풀, Autoscaler 지원)
모니터링	사용자가 로깅 및 모니터링 설정 필요 	Azure Monitor 및 기본 ADF 로그 기능 사용 가능	ISV 솔루션의 로깅 및 모니터링 옵션 제공	Azure Monitor와 AKS Insights를 통해 기본 로그 및 모니터링 제공




Airflow 실습 (K8S) - 현재 AKS와 동일




Helm으로 Airflow Install하여 환경 구성
DAG 파일 작성 및 간단한 코드 설명
Airflow 구성 과정 (PV, PVC, Trouble Shooting(airflow dag ui 안보임, pod 실행안됨, 실행시 모든 task fail(pv와 연결) 등, 리소스 문제 및 조치 설정 ) 일부 소개)
관리의 불편함.
airflow GUI 페이지 소개 (그래프, log 등), 실습 결과 log
트러블슈팅 : webserver pod 실행안됨. → 시간 소요되면 보통 0/1에서 1/1로 실행되나, 시간이 지나도 실행되지 않을때가 있음 → 리소스 수정 필요. (values.yaml에서 timeout 시간, fail threshold 등 수정 필요.)
airflow scheduler 실행 후 web ui에서 실행 시 실패 → host 못찾는 error → PV, PVC 설정하면 해결.




Airflow 실습 (AKS)
1. Airflow 구성과 정상 작동 확인

1-1. Cloud Shell에서 helm으로 설치하여 구성.

helm repo add apache-airflow https://airflow.apache.org
helm repo update
helm install airflow apache-airflow/airflow -n airflow
helm show values apache-airflow/airflow > values.yaml # values.yaml로 airflow 설정 custom
helm install →  Airflow 실행

1-2. DAG 파일 넣고, GUI확인 → 리소스 구성이 로컬에서 airflow를 구동할때와 조금 다를 수 있기 때문에 설정에 유의 필요.

kubectl cp /<dag파일 경로>/firstDag.py <airflow pod namespace>/<airflow-webserver pod>:/opt/airflow/dags/ -n airflow # webserver내부에 dag파일 복사
kubectl exec -it <airflow-webserver pod> -n airflow # webserver 진입
airflow scheduler # 스케쥴러 실행

1-3. airflow scheduler를 실행하고 GUI 확인 → 실행 모습

1-4. graph 및 성공, 실패 log 확인 (아래는 성공예시 → 날짜 log에 표시하는 task)




2. Git Sync
Github과 연동하여 Github에 commit된 dag파일을 가져올 수 있음.

2-1. ssh key 설정 후 github deploy keys에 작성

ssh-keygen -t rsa -b 4096 -C "your_email@example.com" # .ssh 폴더안에서
github deploy keys에 작성




2-2. K8S Secret 생성 (위 ssh key로)

kubectl create secret generic airflow-git-ssh-secret \
  --from-file=gitSshKey=/path/to/.ssh/airflow_ssh_key \
  --from-file=id_ed25519.pub=/path/to/.ssh/airflow_ssh_key.pub \
  -n airflow




2-3. values.yaml 파일 git sync 수정 부분.







2-4. git sync로 github repo와 연결

git sync 이후 github repo에 있던 dag 추가됨.

연동 확인 : tutorial dag → github repo에 commit

Airflow UI에 DAG 추가된 모습

tutorial dag 수행 성공

그래프 확인







3. MetaDB - External DB 연결

3-1. Azure MySQL 서버 생성

3-2. 서버 매개 변수 - require_secure_transport : OFF 설정 (SSL 없이도 접속 가능하게 함)

3-3. private endpoint 설정 - AKS와 같은 Vnet, subnet 설정

AKS와 MySQL 연결 확인 (더미 pod 접속 후 nslookup 명령어)

3-4. mysql 서버와 연결된 phpmyadmin 서버 배포

---
apiVersion: v1
kind: Secret
metadata:
  name: mysql-secrets
type: Opaque
data:
  root-password: TmV3MTIzNCE= # "New1234!" 를 base64로 encode한 값.
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: phpmyadmin-deployment
  labels:
    app: phpmyadmin
spec:
  replicas: 1
  selector:
    matchLabels:
      app: phpmyadmin
  template:
    metadata:
      labels:
        app: phpmyadmin
    spec:
      containers:
        - name: phpmyadmin
          image: phpmyadmin/phpmyadmin
          ports:
            - containerPort: 80
          env:
            - name: PMA_HOST
              value: <mysql 서버 이름>.mysql.database.azure.com
            - name: PMA_PORT
              value: "3306"
            - name: MYSQL_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: mysql-secrets
                  key: root-password  
---				  
apiVersion: v1
kind: Service
metadata:
  name: phpmyadmin-service
spec:
  type: NodePort
  selector:
    app: phpmyadmin
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80	
---	
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: phpmyadmin
  annotations:
    nginx.ingress.kubernetes.io/ssl-passthrough: "true" # nginx-ingress controller 필요.
spec:
  ingressClassName: webapprouting.kubernetes.azure.com
  rules:
  - host: phpjoohan.X.X.X.X.nip.io # 먼저 배포후 AKS의 "서비스 및 수신"에서 ingress controller가 할당한 ip주소로 변경 (X.X.X.X)
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: phpmyadmin-service
            port:
              number: 80 
phpmyadmin pod, ingress 확인

phpmyadmin host 접속 확인




3-5. Airflow 연결 시작 : values.yaml 수정 - 1. metadataConnection 추가 (password에 secret 권장)

airflow.cfg 파일 작성부분




추가 환경변수 설정

airflow db init 수행

3-6. phpmyadmin 내 DB 및 DAG 확인

DAG 추가후







Git Sync를 사용하는 Airflow 환경에서는 Git Sync가 DAG 폴더를 관리하고 동기화하기 때문에, 직접적으로 cp 명령어를 사용해 DAG 폴더에 파일을 추가하더라도 Airflow에서 파일을 인식하지 못함.





